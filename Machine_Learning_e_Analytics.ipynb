{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8RFIQFZXpEwpp2mXLJYq8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrespeedwork/Machine-Learning-Analytics/blob/main/Machine_Learning_e_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introdução\n",
        "\n",
        "Projeto de Machine Learning: Classificação de Emails como Spam ou Não Spam\n",
        "\n",
        "Este projeto visa desenvolver um modelo de Machine Learning para classificar automaticamente emails como spam ou não spam, ajudando a melhorar a experiência do usuário e proteger sistemas contra riscos como phishing e malware. O modelo será treinado usando um dataset de emails e explorará algoritmos como Naive Bayes, SVM e Random Forest para identificar as características que distinguem mensagens legítimas de indesejadas. O processo incluirá pré-processamento dos dados, extração de características e avaliação do desempenho com métricas como acurácia, precisão, recall e F1-score.\n"
      ],
      "metadata": {
        "id": "C_0LaxD4d4lx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparação do ambiente de Machine Learning & Analytics para o desenvolvimento do MVP"
      ],
      "metadata": {
        "id": "1kqcreae0HLS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lelrw2kQY0i2",
        "outputId": "8999973a-a9c4-4b72-b4b6-aee9c174b69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "from google.colab import drive #(Preparando o ambiente para criação do MVP Machine Learning & Analytics)\n",
        "drive.mount('/content/drive'),"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # Biblioteca fundamental para leitura, manipulação e análise de dados estruturados, especialmente em formato de tabelas (DataFrames).\n",
        "import numpy as np # Biblioteca essencial para operações matemáticas e manipulação de grandes arranjos e matrizes multidimensionais, frequentemente usada para processamento de dados numéricos.\n",
        "import matplotlib.pyplot as plt # Biblioteca amplamente utilizada para criação de gráficos e visualizações em 2D, essencial para análise exploratória de dados e apresentação de resultados.\n",
        "from sklearn.model_selection import train_test_split # Função para dividir os dados em conjuntos de treinamento e teste, essencial para avaliar o desempenho do modelo em dados não vistos.\n",
        "from sklearn.preprocessing import StandardScaler # Biblioteca responsável pela padronização dos dados, transformando as características de modo que possuam média zero e desvio padrão igual a um, melhorando a performance de modelos que dependem da escala dos dados.\n",
        "from sklearn.ensemble import RandomForestClassifier # Implementação do algoritmo Random Forest (floresta aleatória), utilizado para classificação e regressão com alta robustez e capacidade de lidar com dados complexos e de alta dimensionalidade.\n",
        "from sklearn.metrics import classification_report # Ferramenta para avaliar modelos de classificação, fornecendo métricas detalhadas como precisão, recall, F1-score e a matriz de confusão.\n",
        "from sklearn.neighbors import KNeighborsClassifier # Implementação do algoritmo k-Nearest Neighbors (KNN), que classifica instâncias com base nas distâncias das instâncias mais próximas do conjunto de treinamento.\n",
        "from sklearn.linear_model import LogisticRegression # Implementação da regressão logística, um modelo estatístico amplamente utilizado para problemas de classificação binária e multiclasse.\n",
        "from sklearn.model_selection import GridSearchCV # Ferramenta para realizar a busca em grade (grid search), que ajuda a otimizar os hiperparâmetros do modelo, encontrando a melhor combinação para melhorar o desempenho do modelo.\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold # Ferramentas para realizar validação cruzada do modelo, com a opção de realizar uma divisão estratificada para garantir a distribuição proporcional das classes em cada fold.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # Ferramenta para transformar dados de texto em representações numéricas, utilizando o método TF-IDF (Term Frequency-Inverse Document Frequency), que calcula a relevância de cada termo em relação ao conjunto de documentos.\n",
        "from sklearn.naive_bayes import MultinomialNB # Implementação do classificador Naive Bayes Multinomial, utilizado principalmente em problemas de classificação de texto, onde as características representam contagens ou frequências de palavras."
      ],
      "metadata": {
        "id": "2O8J_62wZLV_"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ler o arquivo csv, especificando o delimitador e o tratamento de erros\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/andrespeedwork/Machine-Learning-Analytics/refs/heads/main/spam.csv', delimiter=',', on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "UAhlFMW4ZUTM"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir as primeiras linhas do DataFrame\n",
        "print(df.head()) # Mostra as 5 primeiras linhas por padrão e as 5 últimas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVuxG6_eaTPP",
        "outputId": "ac8b7942-29a5-4eba-b3f0-cdaaab6c7e46"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                             v1;v2;;;\n",
            "ham;Go until jurong point                            crazy.. Available only in bugis n great world...\n",
            "ham;Ok lar... Joking wif u oni...;;;                                                              NaN\n",
            "spam;Free entry in 2 a wkly comp to win FA Cup ...                                                NaN\n",
            "ham;U dun say so early hor... U c already then ...                                                NaN\n",
            "ham;Nah I don't think he goes to usf                                   he lives around here though;;;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumo estatístico das colunas numéricas\n",
        "print(df.describe())  # Estatísticas descritivas como média e desvio padrão"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05iy0hX5aYOA",
        "outputId": "bbbe138e-b47e-40c3-a81f-8504413ba59d"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   v1;v2;;;\n",
            "count                   927\n",
            "unique                  828\n",
            "top      I'll call later;;;\n",
            "freq                     30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a dimensão do DataFrame\n",
        "print(f\"Dimensões do dataset: {df.shape}\")  # Número de linhas e colunas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB0OmvAla7Fl",
        "outputId": "75b89b7a-6d84-4650-c94b-d654fe6315eb"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensões do dataset: (5198, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparando e normalizando dados do dataset"
      ],
      "metadata": {
        "id": "t0e4UUYf0SyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar se há valores ausentes\n",
        "print(df.isnull().sum())  # Contagem de valores nulos por coluna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-d7w7ixfL-E",
        "outputId": "e471f57c-ad6a-42ec-a162-7e6ca69a254d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v1;v2;;;    4271\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratar valores ausentes\n",
        "df = df.dropna()  # Remove linhas com valores nulos (ou use imputação)"
      ],
      "metadata": {
        "id": "n0Bwkz40fQK0"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar o dataset após o tratamento dos valores ausentes\n",
        "print(df.isnull().sum())  # Contagem de valores nulos por coluna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8r5CFzSfSyA",
        "outputId": "aed466b3-a309-4ffb-a7be-f20ee328d836"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v1;v2;;;    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a dimensão do DataFrame após o tratamento dos valores ausentes\n",
        "print(f\"Dimensões do dataset: {df.shape}\")  # Número de linhas e colunas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXGjLqJ9gF4O",
        "outputId": "0819feca-37ce-4c19-fc34-83fc709292f6"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensões do dataset: (927, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset usando delimitador\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/andrespeedwork/Machine-Learning-Analytics/refs/heads/main/spam.csv', encoding='latin-1', delimiter=';')\n",
        "# Setando o ';' para corrigir o arquivo\n",
        "df = df[['v1', 'v2']]  # Ajuste para separar rótulos e mensagens\n",
        "df.columns = ['label', 'text']\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})  # Codificação binária"
      ],
      "metadata": {
        "id": "af-Ala5Zg-ki"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformando um conjunto de textos em representações numéricas\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "5kNF1j-dhBmM"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dividindo o dataset entre treino e teste"
      ],
      "metadata": {
        "id": "lQmQv6So8vDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo o dataset entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "aIwIWcdChSzD"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo e validação cruzada\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
        "\n",
        "print(f\"F1-Score médio: {scores.mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An72AMeyhWNg",
        "outputId": "d7c35cef-3553-4d85-c85a-b38732d793a4"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score médio: 0.8920159623763471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinando e testando o modelo"
      ],
      "metadata": {
        "id": "wyHnQHhM8_KY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando teste e treino\n",
        "#model.fit(X_train, y_train)\n",
        "#y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Kvqyw-85hbSQ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinando o modelo com alguns algoritimos"
      ],
      "metadata": {
        "id": "kBaXpMAB9Owj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Avaliação\n",
        "print(\"Random Forest Classifier\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "q3BUa2gfhqZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Avaliação\n",
        "print(\"Logistic Regression\")\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "4t6GJmG_hvdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Nearest Neighbors (KNN)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Avaliação\n",
        "print(\"K-Nearest Neighbors\")\n",
        "print(classification_report(y_test, y_pred_knn))"
      ],
      "metadata": {
        "id": "NdRMAtNwh5_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar KNN com Cross-Validation\n",
        "\n",
        "#Aqui, usamos a validação cruzada com o modelo KNN para avaliar o desempenho.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "# Configurar validação cruzada\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Treinar o modelo KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # Começando com k=5\n",
        "scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Resultados\n",
        "print(f\"Acurácias por dobra: {scores}\")\n",
        "print(f\"Acurácia média: {scores.mean():.4f}\")"
      ],
      "metadata": {
        "id": "OOy7b6zXGRAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relatório final\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "k3GOouuxGRgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ajustando Hiperparâmetros\n",
        "Neste caso escolhi trabalhar com KNN"
      ],
      "metadata": {
        "id": "CJxMphzL-LjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Para melhorar o desempenho, ajuste os hiperparâmetros dos modelos. Exemplos:\n",
        "\n",
        "#    Para Random Forest: Ajuste n_estimators, max_depth, etc.\n",
        "#   Para KNN: Teste diferentes valores para n_neighbors.\n",
        "\n",
        "# Exemplo com GridSearchCV:\n",
        "\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Parâmetros para ajustar no KNN\n",
        "param_grid = {'n_neighbors': [3, 5, 7, 9]}\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"Melhores parâmetros para KNN:\", grid_knn.best_params_)"
      ],
      "metadata": {
        "id": "mC7hBxvQh_TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajuste do Número de Vizinhos (k)\n",
        "\n",
        "# Teste diferentes valores de k para encontrar o melhor.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "k_values = range(1,15)\n",
        "mean_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
        "    mean_scores.append(scores.mean())\n",
        "\n",
        "# Plotar o desempenho\n",
        "plt.plot(k_values, mean_scores, marker='o')\n",
        "plt.xlabel(\"Número de Vizinhos (k)\")\n",
        "plt.ylabel(\"Acurácia Média\")\n",
        "plt.title(\"Desempenho do KNN com diferentes valores de k\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Melhor k\n",
        "best_k = k_values[mean_scores.index(max(mean_scores))]\n",
        "print(f\"Melhor valor de k: {best_k}\")"
      ],
      "metadata": {
        "id": "1pW602cHiHgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento Final com o Melhor k\n",
        "\n",
        "# Após encontrar o melhor valor de k, treine o modelo novamente e avalie o desempenho.\n",
        "\n",
        "# Melhor KNN\n",
        "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
        "\n",
        "# Avaliação com validação cruzada\n",
        "final_scores = cross_val_score(knn_best, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "print(f\"Melhor KNN - Acurácias por dobra: {final_scores}\")\n",
        "print(f\"Melhor KNN - Acurácia média: {final_scores.mean():.4f}\")"
      ],
      "metadata": {
        "id": "QBK_b4w8iPuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação no Conjunto de Teste\n",
        "\n",
        "#Divida os dados em treino e teste para avaliar o modelo no conjunto de teste.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Separar conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Treinar o modelo com o melhor k\n",
        "knn_best.fit(X_train, y_train)\n",
        "y_pred = knn_best.predict(X_test)\n",
        "\n",
        "# Avaliar desempenho\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "dzY7VfgOiUEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX** Checklist sugerido:"
      ],
      "metadata": {
        "id": "irCrFnluiagx"
      }
    }
  ]
}