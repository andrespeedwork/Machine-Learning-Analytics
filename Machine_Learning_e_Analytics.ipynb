{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeYZRy4PUclGevQWkzh18G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrespeedwork/Machine-Learning-Analytics/blob/main/Machine_Learning_e_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introdução\n",
        "\n",
        "Projeto de Machine Learning: Classificação de Emails como Spam ou Não Spam\n",
        "\n",
        "Este projeto visa desenvolver um modelo de Machine Learning para classificar automaticamente emails como spam ou não spam, ajudando a melhorar a experiência do usuário e proteger sistemas contra riscos como phishing e malware. O modelo será treinado usando um dataset de emails e explorará algoritmos como Naive Bayes, SVM e Random Forest para identificar as características que distinguem mensagens legítimas de indesejadas. O processo incluirá pré-processamento dos dados, extração de características e avaliação do desempenho com métricas como acurácia, precisão, recall e F1-score.\n"
      ],
      "metadata": {
        "id": "C_0LaxD4d4lx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparação do ambiente de Machine Learning & Analytics para o desenvolvimento do MVP"
      ],
      "metadata": {
        "id": "1kqcreae0HLS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lelrw2kQY0i2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive #(Preparando o ambiente para criação do MVP Machine Learning & Analytics)\n",
        "drive.mount('/content/drive'),"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # Biblioteca fundamental para leitura, manipulação e análise de dados estruturados, especialmente em formato de tabelas (DataFrames).\n",
        "import numpy as np # Biblioteca essencial para operações matemáticas e manipulação de grandes arranjos e matrizes multidimensionais, frequentemente usada para processamento de dados numéricos.\n",
        "import matplotlib.pyplot as plt # Biblioteca amplamente utilizada para criação de gráficos e visualizações em 2D, essencial para análise exploratória de dados e apresentação de resultados.\n",
        "from sklearn.model_selection import train_test_split # Função para dividir os dados em conjuntos de treinamento e teste, essencial para avaliar o desempenho do modelo em dados não vistos.\n",
        "from sklearn.preprocessing import StandardScaler # Biblioteca responsável pela padronização dos dados, transformando as características de modo que possuam média zero e desvio padrão igual a um, melhorando a performance de modelos que dependem da escala dos dados.\n",
        "from sklearn.ensemble import RandomForestClassifier # Implementação do algoritmo Random Forest (floresta aleatória), utilizado para classificação e regressão com alta robustez e capacidade de lidar com dados complexos e de alta dimensionalidade.\n",
        "from sklearn.metrics import classification_report # Ferramenta para avaliar modelos de classificação, fornecendo métricas detalhadas como precisão, recall, F1-score e a matriz de confusão.\n",
        "from sklearn.neighbors import KNeighborsClassifier # Implementação do algoritmo k-Nearest Neighbors (KNN), que classifica instâncias com base nas distâncias das instâncias mais próximas do conjunto de treinamento.\n",
        "from sklearn.linear_model import LogisticRegression # Implementação da regressão logística, um modelo estatístico amplamente utilizado para problemas de classificação binária e multiclasse.\n",
        "from sklearn.model_selection import GridSearchCV # Ferramenta para realizar a busca em grade (grid search), que ajuda a otimizar os hiperparâmetros do modelo, encontrando a melhor combinação para melhorar o desempenho do modelo.\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold # Ferramentas para realizar validação cruzada do modelo, com a opção de realizar uma divisão estratificada para garantir a distribuição proporcional das classes em cada fold.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # Ferramenta para transformar dados de texto em representações numéricas, utilizando o método TF-IDF (Term Frequency-Inverse Document Frequency), que calcula a relevância de cada termo em relação ao conjunto de documentos.\n",
        "from sklearn.naive_bayes import MultinomialNB # Implementação do classificador Naive Bayes Multinomial, utilizado principalmente em problemas de classificação de texto, onde as características representam contagens ou frequências de palavras."
      ],
      "metadata": {
        "id": "2O8J_62wZLV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ler o arquivo csv, especificando o delimitador e o tratamento de erros\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/andrespeedwork/Machine-Learning-Analytics/refs/heads/main/spam.csv', delimiter=',', on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "UAhlFMW4ZUTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir as primeiras linhas do DataFrame\n",
        "print(df.head()) # Mostra as 5 primeiras linhas por padrão e as 5 últimas"
      ],
      "metadata": {
        "id": "LVuxG6_eaTPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumo estatístico das colunas numéricas\n",
        "print(df.describe())  # Estatísticas descritivas como média e desvio padrão"
      ],
      "metadata": {
        "id": "05iy0hX5aYOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a dimensão do DataFrame\n",
        "print(f\"Dimensões do dataset: {df.shape}\")  # Número de linhas e colunas"
      ],
      "metadata": {
        "id": "pB0OmvAla7Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparando e normalizando dados do dataset"
      ],
      "metadata": {
        "id": "t0e4UUYf0SyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar se há valores ausentes\n",
        "print(df.isnull().sum())  # Contagem de valores nulos por coluna"
      ],
      "metadata": {
        "id": "u-d7w7ixfL-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratar valores ausentes\n",
        "df = df.dropna()  # Remove linhas com valores nulos (ou use imputação)"
      ],
      "metadata": {
        "id": "n0Bwkz40fQK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar o dataset após o tratamento dos valores ausentes\n",
        "print(df.isnull().sum())  # Contagem de valores nulos por coluna"
      ],
      "metadata": {
        "id": "Q8r5CFzSfSyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a dimensão do DataFrame após o tratamento dos valores ausentes\n",
        "print(f\"Dimensões do dataset: {df.shape}\")  # Número de linhas e colunas"
      ],
      "metadata": {
        "id": "tXGjLqJ9gF4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset usando delimitador\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/andrespeedwork/Machine-Learning-Analytics/refs/heads/main/spam.csv', encoding='latin-1', delimiter=';')\n",
        "# Setando o ';' para corrigir o arquivo\n",
        "df = df[['v1', 'v2']]  # Ajuste para separar rótulos e mensagens\n",
        "df.columns = ['label', 'text']\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})  # Codificação binária"
      ],
      "metadata": {
        "id": "af-Ala5Zg-ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformando um conjunto de textos em representações numéricas\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "5kNF1j-dhBmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dividindo o dataset entre treino e teste"
      ],
      "metadata": {
        "id": "lQmQv6So8vDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo o dataset entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "aIwIWcdChSzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Normalizar os dados (apenas X)\n",
        "scaler = StandardScaler(with_mean=False) # Set with_mean=False to avoid centering\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "EqWJd21qLmpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy import sparse\n",
        "\n",
        "# Assuming X is your csr_matrix\n",
        "X_dense = X.toarray()  # Convert sparse matrix to a dense NumPy array\n",
        "\n",
        "# Now you can plot the histogram\n",
        "plt.hist(X_dense.flatten(), bins=20, edgecolor='black')  # Flatten for a single histogram\n",
        "plt.suptitle('Distribuição das Variáveis (Features)', fontsize=16)\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "L1aNPSkBL11Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming X is your csr_matrix\n",
        "X_dense = X.toarray()  # Convert sparse matrix to dense NumPy array\n",
        "df = pd.DataFrame(X_dense)  # Create a pandas DataFrame from the dense array\n",
        "\n",
        "# Heatmap de correlação entre as variáveis\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = df.corr()  # Calculate correlation using the DataFrame\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n",
        "plt.title('Mapa de Correlação entre Variáveis', fontsize=16)\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "K-P7dVGqMXnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo e validação cruzada\n",
        "model = MultinomialNB()\n",
        "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
        "\n",
        "print(f\"F1-Score médio: {scores.mean()}\")"
      ],
      "metadata": {
        "id": "An72AMeyhWNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinando e testando o modelo"
      ],
      "metadata": {
        "id": "wyHnQHhM8_KY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinando o modelo com alguns algoritimos"
      ],
      "metadata": {
        "id": "kBaXpMAB9Owj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Avaliação\n",
        "print(\"Random Forest Classifier\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "q3BUa2gfhqZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Avaliação\n",
        "print(\"Logistic Regression\")\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "4t6GJmG_hvdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Nearest Neighbors (KNN)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Avaliação\n",
        "print(\"K-Nearest Neighbors\")\n",
        "print(classification_report(y_test, y_pred_knn))"
      ],
      "metadata": {
        "id": "NdRMAtNwh5_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ajustando Hiperparâmetros\n",
        "Neste caso escolhi trabalhar com KNN"
      ],
      "metadata": {
        "id": "CJxMphzL-LjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar KNN com Cross-Validation\n",
        "\n",
        "#Aqui, usamos a validação cruzada com o modelo KNN para avaliar o desempenho.\n",
        "\n",
        "# Configurar validação cruzada\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Treinar o modelo KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # Começando com k=5\n",
        "scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Resultados\n",
        "print(f\"Acurácias por dobra: {scores}\")\n",
        "print(f\"Acurácia média: {scores.mean():.4f}\")"
      ],
      "metadata": {
        "id": "AsR5MLKII4Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Para melhorar o desempenho, ajuste os hiperparâmetros dos modelos. Exemplos:\n",
        "\n",
        "#    Para Random Forest: Ajuste n_estimators, max_depth, etc.\n",
        "#   Para KNN: Teste diferentes valores para n_neighbors.\n",
        "\n",
        "# Exemplo com GridSearchCV:\n",
        "\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Parâmetros para ajustar no KNN\n",
        "param_grid = {'n_neighbors': [3, 5, 7, 9]}\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"Melhores parâmetros para KNN:\", grid_knn.best_params_)"
      ],
      "metadata": {
        "id": "mC7hBxvQh_TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajuste do Número de Vizinhos (k)\n",
        "\n",
        "# Teste diferentes valores de k para encontrar o melhor.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "k_values = range(1,15)\n",
        "mean_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
        "    mean_scores.append(scores.mean())\n",
        "\n",
        "# Plotar o desempenho\n",
        "plt.plot(k_values, mean_scores, marker='o')\n",
        "plt.xlabel(\"Número de Vizinhos (k)\")\n",
        "plt.ylabel(\"Acurácia Média\")\n",
        "plt.title(\"Desempenho do KNN com diferentes valores de k\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Melhor k\n",
        "best_k = k_values[mean_scores.index(max(mean_scores))]\n",
        "print(f\"Melhor valor de k: {best_k}\")"
      ],
      "metadata": {
        "id": "1pW602cHiHgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento Final com o Melhor k\n",
        "\n",
        "# Após encontrar o melhor valor de k, treine o modelo novamente e avalie o desempenho.\n",
        "\n",
        "# Melhor KNN\n",
        "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
        "\n",
        "# Avaliação com validação cruzada\n",
        "final_scores = cross_val_score(knn_best, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "print(f\"Melhor KNN - Acurácias por dobra: {final_scores}\")\n",
        "print(f\"Melhor KNN - Acurácia média: {final_scores.mean():.4f}\")"
      ],
      "metadata": {
        "id": "QBK_b4w8iPuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação no Conjunto de Teste\n",
        "\n",
        "#Divida os dados em treino e teste para avaliar o modelo no conjunto de teste.\n",
        "\n",
        "# Separar conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Treinar o modelo com o melhor k\n",
        "knn_best.fit(X_train, y_train)\n",
        "y_pred = knn_best.predict(X_test)\n",
        "\n",
        "# Avaliar desempenho\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "dzY7VfgOiUEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX** Checklist sugerido:"
      ],
      "metadata": {
        "id": "irCrFnluiagx"
      }
    }
  ]
}